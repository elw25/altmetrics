---
title: "On the origin of Stuff"
author: "Erica Westerman"
date: "September 15, 2015"
output: 
  html_document:
    toc: true
    number_sections: true
    theme: cerulean
    highlight: espresso
    fig_width: 8
    fig_height: 8
    fig_caption: yes
---

#Load the data
## second header!
```{r load_data}
counts_raw <- read.delim("data/counts-raw.txt.gz")
counts_norm <- read.delim("data/counts-norm.txt.gz")

```

# Data exploration
What's the distribution of authors in all articles of our data set?

```{r histogram, fig.cap="Figure1:Authors"}
hist(counts_raw$authorsCount, main = "Authors per paper", xlab = " # authors")

```

##loops!
```{r}

```

for (i in c("cat","dog","cow")) {
  print("TACOS!")
}
x<- numeric()

for (i in 1:length(counts_raw$wosCountThru2011)) {
  x[i] <- c( x, counts_raw$wosCountThru2011[i]+1)
}

levels (counts_raw$journal)
results <- numeric(length = length(levels(counts_raw$journal)))
results
names(results) <- levels(counts_raw$journal)
results

for (j in levels(counts_raw$journal)) {
  results[j] <- mean(counts_raw$wosCountTrh2011[counts_raw$jounral == j])
}

for (i in 1:10) {
  print (i)
}

x <- numeric(length=length(counts_raw$wosCountThru2011))
for (i in 1:length(counts_raw$wosCountThru2011)) {
  x[i] <- counts_raw$wosCountThru2011[i] + 1
}
 
## selection with dplyr
 
```{r dplyr}
library("dplyr")
```


```{r}
research <- filter(counts_raw, articleType == "Research Article")
```

```{r}
research_2006 <- filter(research, year == 2006)
nrow(research_2006)
research_2006_tweet <- filter(research_2006, backtweetsCount > 0)
nrow(research_2006_tweet)
research_2006_fb <- filter(research, year == 2006,
                           facebookCommentCount > 0)
nrow(research_2006_fb)
research_2006_fb_tweet <- filter(research, year == 2006,
                                 facebookCommentCount > 0 |
                                 backtweetsCount > 0)
nrow(research_2006_fb_tweet)
```
## grep stuff with dplyr
```{r}
research_2006_fb_tweet_disease <- filter(research, year == 2006,
                                         facebookCommentCount > 0 |
                                         backtweetsCount > 0,
                                         grepl("Infectious Diseases",
                                               plosSubjectTags))
nrow(research_2006_fb_tweet_disease)
```
## selecting with dplyr
```{r}
colnames(research)
```
##now I'm naming stuff for selection to make subset data frames
```{r}
article_info <- select(research, doi, pubDate, journal, title,
                       articleType, authorsCount)
colnames(article_info)
metrics <- select(research, contains("Count"))
colnames(metrics)
metrics <- select(research, contains("Count"), -authorsCount)
colnames(metrics)
metrics <- select(research, contains("Count"), -authorsCount,
                  f1000Factor, wikipediaCites)
colnames(metrics)
```
## simplifying dplyr
```{r}
head(select(research, journal))
head(select(research, 3))
slice(article_info, 1:3)
```
##piping
```{r}
facebook_2006 <-research %>% filter(year == 2006) %>% 
  select(contains("facebook"))
head(facebook_2006)
```
arrange, works similar to function order 
piping is supposed to work with %>%. However, this doesn't seem to always work for me. 
```{r}
research %>% arrange(authorsCount, wosCountThru2011) %>% select(authorsCount, wosCountThru2011) %>% slice(1:10)
```
##Creating new columns with dpylr
```{r}
research <- mutate(research,
                   weeksSincePublished = daysSincePublished / 7,
                   yearsSincePublished = weeksSincePublished / 52)
select(research, contains("Since")) %>% slice(1:10)
```
## using summarize
```{r}
summarize(research, plos_mean = mean(plosCommentCount),plos_sd = sd(plosCommentCount))
```
and I can summarize and pipe
```{r}
research %>% filter(journal == "pone", year == 2007) %>% summarize(plos_mean = mean(plosCommentCount),plos_sd = sd(plosCommentCount))
```
some more
```{r}
research %>% filter(journal == "pone", year == 2007) %>% summarize(plos_mean = mean(plosCommentCount), plos_sd = sd(plosCommentCount), num = n())
```

## summarizing using group by!

```{r}
research %>% group_by(journal) %>% summarize(tweets_mean = mean(backtweetsCount))
```
 further grouping
 
```{r}
research %>% group_by(journal, year) %>% summarize(tweets_mean = mean(backtweetsCount))
```

```{r}
tweets_per_journal <- research %>% group_by(journal) %>% summarize(num = n(), mean = mean(backtweetsCount), sem = sd(backtweetsCount) /sqrt(num)) 
tweets_per_journal

```
##Doing Cool Stuff with ggplot
```{r}
library("ggplot2")
```
ggplot uses data frames. The different axes are called aesthetics.
we can build layers on our graph. IT won't plot if there are no layers. Add on layers before p, so one doesn't get confused as to which layer is which
```{r}
p <- ggplot(dat = research, mapping = aes(x=pdfDownloadsCount, y= wosCountThru2011)) + geom_point(aes(color = journal))
p
```
can also add size
```{r}
p <- ggplot(dat = research, mapping = aes(x=pdfDownloadsCount, y= wosCountThru2011)) + geom_point(aes(size = authorsCount))
p
```
Can also make transparency scale
```{r}
p <- ggplot(dat = research, mapping = aes(x=pdfDownloadsCount, y= wosCountThru2011)) + geom_point(aes(alpha = daysSincePublished))
p
```
aes allows for updating by data in frame. Can also manipulate visualization by just defining outside of aes (ie color="red")
```{r}
p <- ggplot(dat = research, mapping = aes(x=pdfDownloadsCount, y= wosCountThru2011, color = journal)) + geom_smooth()

p
```
this makes a smoothing line per journal, each of which is colored. How cool is that!

Here, I've added a line of best fit as well as colored the data by journal
```{r}
p <- ggplot(dat = research, mapping = aes(x=daysSincePublished, y= wosCountThru2011)) + geom_point(aes(color = journal), alpha=0.5) + geom_smooth(color = "red")
p
```
 ## Using scales to make things look better!
 
```{r}
p <- ggplot(dat = research, mapping = aes(x=log10(pdfDownloadsCount + 1), y= wosCountThru2011)) + geom_point(aes(color = journal))+ geom_smooth()
p + scale_x_log10() + scale_y_log10()
```
can also modify aesthetics
```{r}
p <- ggplot(dat = research, mapping = aes(x=log10(pdfDownloadsCount + 1), y=log10( wosCountThru2011 + 1))) + geom_point(aes(color = journal))+ geom_smooth()
p  
```
more ways to influence scale (again, if error, check where those parantheses are!)
```{r}
p <- ggplot(dat = research, mapping = aes(x=log10(pdfDownloadsCount + 1), y=log10(wosCountThru2011 + 1))) + geom_point(aes(color = journal))+ geom_smooth() + scale_x_continuous(breaks = c(1,3), labels = c(10, 1000)) + scale_y_continuous(breaks = c(1,3), labels = c(10, 1000), limits = c(1,3))
p
```

can make it different in color
```{r}
p <- ggplot(dat = research, mapping = aes(x=log10(pdfDownloadsCount + 1), y=log10(wosCountThru2011 + 1))) + geom_point(aes(color = journal))+ geom_smooth() + scale_x_continuous(breaks = c(1,3), labels = c(10, 1000)) + scale_y_continuous(breaks = c(1,3), labels = c(10, 1000), limits = c(1,3))
p+ scale_color_brewer(palette = "Dark2")
```

can update labels and names 

```{r}
p + scale_color_brewer(palette= "Dark2", labels = 1:7, name = "PLOS")
```
 change the manipulation
 
```{r}
p <- ggplot(dat = research, mapping = aes(x=sqrt(pdfDownloadsCount), y=sqrt(wosCountThru2011))) + geom_point(aes(color = journal))+ geom_smooth()

p + scale_color_brewer(palette = "Accent", labels = 1:7, name = "PLOS")
```
subplots!
```{r}
p <- ggplot(dat = research, mapping = aes(x=log10(pdfDownloadsCount + 1), y=log10(wosCountThru2011 + 1))) + geom_point(aes(color = journal))+ geom_smooth() + scale_x_continuous(breaks = c(1,3), labels = c(10, 1000)) + scale_y_continuous(breaks = c(1,3), labels = c(10, 1000), limits = c(1,3))
p + facet_wrap(journal)
```

